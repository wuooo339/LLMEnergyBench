VLLM_ALLOW_LONG_MAX_MODEL_LEN=1 CUDA_VISIBLE_DEVICES=0,1 python benchmark_vllm_offline.py --model-shortcut meta-llama-7b --gpu-ids 0 1 --batch-size 110 --num-iters 3 --run-id test-tp --use-splitwise --use-dummy-inputs --input-len 160 --output-len 140 --use-online-ttft --prefill-num-iters 1 --num-iters-warmup 0 --tensor-parallel-size 2 --gpu-memory-utilization 0.99 --enforce-eager 
